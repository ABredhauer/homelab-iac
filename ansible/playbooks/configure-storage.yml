# ansible/playbooks/configure-storage.yml
# Phase 3: Storage Configuration (v6 - Fixed ZFS pool name)
# - Mount NFS shares from NAS
# - Create test VM on local ZFS storage (RPOOL - not local-zfs!)
# - Configure and test ZFS replication between cluster nodes
# - Set up backup schedule (4-week retention)
# - Add memory monitoring (no swap configuration)

---
- name: Configure NFS Storage on All Cluster Nodes
  hosts: proxmox_cluster_members
  become: true
  gather_facts: true
  strategy: linear

  vars:
    nas_ip: "192.168.1.25"

    nfs_shares:
      backup:
        export_path: "/volume1/backups/proxmox"
        mount_point: "/mnt/pve/nas-backup"
        storage_id: "nas-backup"
        content_types: "backup"
        mount_options: "rw,async,hard,nolock"

      shared:
        export_path: "/volume1/homelab-shared"
        mount_point: "/mnt/pve/nas-shared"
        storage_id: "nas-shared"
        content_types: "iso,vztmpl,snippets"
        mount_options: "rw,sync,hard,nolock"

      vm_storage:
        export_path: "/volume1/homelab-data"
        mount_point: "/mnt/pve/nas-vm-storage"
        storage_id: "nas-vm-storage"
        content_types: "images,rootdir"
        mount_options: "rw,sync,hard,nolock"

  tasks:
    - name: Display storage configuration plan
      ansible.builtin.debug:
        msg: |
          Phase 3: Storage Configuration
          ==============================
          Node: {{ inventory_hostname }}

          NFS Mounts (from {{ nas_ip }}):
            1. {{ nfs_shares.backup.export_path }} -> {{ nfs_shares.backup.storage_id }}
            2. {{ nfs_shares.shared.export_path }} -> {{ nfs_shares.shared.storage_id }}
            3. {{ nfs_shares.vm_storage.export_path }} -> {{ nfs_shares.vm_storage.storage_id }}

          ZFS Replication: 5-minute interval (test VM only)
          Backup Schedule: Weekly (Sunday 2AM), 4-week retention

    # ===== PHASE 1: INSTALL NFS CLIENT =====
    - name: Install NFS client packages
      ansible.builtin.apt:
        name:
          - nfs-common
          - nfs4-acl-tools
        state: present
        update_cache: true

    # ===== PHASE 2: CHECK AND CREATE MOUNT POINTS (IDEMPOTENT) =====
    - name: Check if backup mount point exists
      ansible.builtin.stat:
        path: "{{ nfs_shares.backup.mount_point }}"
      register: backup_mount_exists

    - name: Create backup mount point directory
      ansible.builtin.file:
        path: "{{ nfs_shares.backup.mount_point }}"
        state: directory
        mode: '0755'
      when: not backup_mount_exists.stat.exists

    - name: Check if shared mount point exists
      ansible.builtin.stat:
        path: "{{ nfs_shares.shared.mount_point }}"
      register: shared_mount_exists

    - name: Create shared mount point directory
      ansible.builtin.file:
        path: "{{ nfs_shares.shared.mount_point }}"
        state: directory
        mode: '0755'
      when: not shared_mount_exists.stat.exists

    - name: Check if vm_storage mount point exists
      ansible.builtin.stat:
        path: "{{ nfs_shares.vm_storage.mount_point }}"
      register: vm_storage_mount_exists

    - name: Create vm_storage mount point directory
      ansible.builtin.file:
        path: "{{ nfs_shares.vm_storage.mount_point }}"
        state: directory
        mode: '0755'
      when: not vm_storage_mount_exists.stat.exists

    # ===== PHASE 3: MOUNT NFS SHARES (IDEMPOTENT) =====
    - name: Check if backup share is mounted
      ansible.builtin.shell: |
        set -o pipefail
        mountpoint -q {{ nfs_shares.backup.mount_point }}
      register: backup_mounted
      failed_when: false
      changed_when: false

    - name: Mount backup share
      ansible.posix.mount:
        path: "{{ nfs_shares.backup.mount_point }}"
        src: "{{ nas_ip }}:{{ nfs_shares.backup.export_path }}"
        fstype: nfs
        opts: "{{ nfs_shares.backup.mount_options }}"
        state: mounted
      when: backup_mounted.rc != 0

    - name: Check if shared storage is mounted
      ansible.builtin.shell: |
        set -o pipefail
        mountpoint -q {{ nfs_shares.shared.mount_point }}
      register: shared_mounted
      failed_when: false
      changed_when: false

    - name: Mount shared storage
      ansible.posix.mount:
        path: "{{ nfs_shares.shared.mount_point }}"
        src: "{{ nas_ip }}:{{ nfs_shares.shared.export_path }}"
        fstype: nfs
        opts: "{{ nfs_shares.shared.mount_options }}"
        state: mounted
      when: shared_mounted.rc != 0

    - name: Check if vm_storage is mounted
      ansible.builtin.shell: |
        set -o pipefail
        mountpoint -q {{ nfs_shares.vm_storage.mount_point }}
      register: vm_storage_mounted
      failed_when: false
      changed_when: false

    - name: Mount vm_storage
      ansible.posix.mount:
        path: "{{ nfs_shares.vm_storage.mount_point }}"
        src: "{{ nas_ip }}:{{ nfs_shares.vm_storage.export_path }}"
        fstype: nfs
        opts: "{{ nfs_shares.vm_storage.mount_options }}"
        state: mounted
      when: vm_storage_mounted.rc != 0

    - name: Verify NFS mounts are accessible
      ansible.builtin.shell: ls -la {{ nfs_shares.backup.mount_point }} && echo "backup ok"
      register: mount_verify
      changed_when: false
      retries: 3
      delay: 2

    - name: Display mount status
      ansible.builtin.debug:
        msg: "NFS mounts verified and accessible"

    # ===== PHASE 4: CREATE SUBDIRECTORIES ON NFS SHARES =====
    - name: Create template directories in shared storage
      ansible.builtin.file:
        path: "{{ nfs_shares.shared.mount_point }}/{{ item }}"
        state: directory
        mode: '0755'
      loop:
        - template/iso
        - template/cache
        - snippets
      delegate_to: "{{ groups['proxmox_cluster_members'][0] }}"
      run_once: true

    # ===== PHASE 5: ADD NFS STORAGE TO PROXMOX =====
    - name: Check if backup storage already exists
      ansible.builtin.shell: |
        set -o pipefail
        pvesm status | grep -q "{{ nfs_shares.backup.storage_id }}"
      register: backup_storage_exists
      failed_when: false
      changed_when: false
      run_once: true

    - name: Add backup storage to Proxmox
      ansible.builtin.command: >
        pvesm add nfs {{ nfs_shares.backup.storage_id }}
        --server {{ nas_ip }}
        --export {{ nfs_shares.backup.export_path }}
        --path {{ nfs_shares.backup.mount_point }}
        --content {{ nfs_shares.backup.content_types }}
        --options {{ nfs_shares.backup.mount_options }}
      run_once: true
      when: backup_storage_exists.rc != 0

    - name: Check if shared storage already exists
      ansible.builtin.shell: |
        set -o pipefail
        pvesm status | grep -q "{{ nfs_shares.shared.storage_id }}"
      register: shared_storage_exists
      failed_when: false
      changed_when: false
      run_once: true

    - name: Add shared resources storage to Proxmox
      ansible.builtin.command: >
        pvesm add nfs {{ nfs_shares.shared.storage_id }}
        --server {{ nas_ip }}
        --export {{ nfs_shares.shared.export_path }}
        --path {{ nfs_shares.shared.mount_point }}
        --content {{ nfs_shares.shared.content_types }}
        --options {{ nfs_shares.shared.mount_options }}
      run_once: true
      when: shared_storage_exists.rc != 0

    - name: Check if vm_storage already exists
      ansible.builtin.shell: |
        set -o pipefail
        pvesm status | grep -q "{{ nfs_shares.vm_storage.storage_id }}"
      register: vm_storage_exists
      failed_when: false
      changed_when: false
      run_once: true

    - name: Add VM storage to Proxmox
      ansible.builtin.command: >
        pvesm add nfs {{ nfs_shares.vm_storage.storage_id }}
        --server {{ nas_ip }}
        --export {{ nfs_shares.vm_storage.export_path }}
        --path {{ nfs_shares.vm_storage.mount_point }}
        --content {{ nfs_shares.vm_storage.content_types }}
        --options {{ nfs_shares.vm_storage.mount_options }}
      run_once: true
      when: vm_storage_exists.rc != 0

    - name: Verify Proxmox storage configuration
      ansible.builtin.command: pvesm status
      register: storage_status
      changed_when: false

    - name: Display storage status
      ansible.builtin.debug:
        msg: "{{ storage_status.stdout_lines }}"

    # ===== PHASE 6: CONFIGURE ZFS PROPERTIES =====
    - name: Optimize ZFS dataset for VM storage
      ansible.builtin.command: "{{ item }}"
      loop:
        - "zfs set compression=lz4 rpool/data"
        - "zfs set atime=off rpool/data"
        - "zfs set recordsize=128k rpool/data"
        - "zfs set xattr=sa rpool/data"
      register: zfs_config
      changed_when: zfs_config.rc == 0
      failed_when: false

    # ===== PHASE 7: MEMORY MONITORING (NO SWAP) =====
    - name: Install memory monitoring tools
      ansible.builtin.apt:
        name:
          - sysstat
          - atop
        state: present

    - name: Create memory monitoring script
      ansible.builtin.copy:
        dest: /usr/local/bin/check-memory-pressure.sh
        mode: '0755'
        content: |
          #!/bin/bash
          # Memory pressure monitoring (no swap configured)

          TOTAL=$(free -m | awk '/^Mem:/ {print $2}')
          USED=$(free -m | awk '/^Mem:/ {print $3}')
          PERCENT=$((USED * 100 / TOTAL))

          if [ $PERCENT -gt 90 ]; then
            echo "WARNING: Memory usage at ${PERCENT}%" | wall
            logger -p user.warning -t memory-check "High memory pressure: ${PERCENT}% used (${USED}MB/${TOTAL}MB)"
            ps aux --sort=-%mem | head -n 6 | logger -p user.info -t memory-check
          fi

    - name: Schedule memory monitoring (every 5 minutes)
      ansible.builtin.cron:
        name: "Memory pressure monitoring"
        minute: "*/5"
        job: "/usr/local/bin/check-memory-pressure.sh"
        user: root

    - name: Create memory check alias in bashrc
      ansible.builtin.lineinfile:
        path: /root/.bashrc
        line: alias memcheck='free -h && echo && echo "Top 10 memory consumers:" && ps aux --sort=-%mem | head -n 11'
        state: present

    # ===== PHASE 8: CREATE COMPLETION MARKER =====
    - name: Create storage configuration completion marker
      ansible.builtin.copy:
        dest: /opt/storage-config-complete
        content: |
          Storage Configuration Complete
          ==============================
          Node: {{ inventory_hostname }}
          Timestamp: {{ ansible_date_time.iso8601 }}

          NFS Storage Configured:
            - {{ nfs_shares.backup.storage_id }} ({{ nfs_shares.backup.export_path }})
            - {{ nfs_shares.shared.storage_id }} ({{ nfs_shares.shared.export_path }})
            - {{ nfs_shares.vm_storage.storage_id }} ({{ nfs_shares.vm_storage.export_path }})

          ZFS Configuration:
            - Pool: rpool
            - Compression: lz4
            - Record size: 128k
            - Atime: off

          Memory Monitoring:
            - Enabled (no swap configured)
            - Check interval: 5 minutes
            - Alert threshold: 90%
        mode: '0644'


# ===== PLAY 2: Create Test VM for Replication Testing =====
- name: Create Test VM on Master Node
  hosts: proxmox_cluster_masters
  become: true
  gather_facts: true
  strategy: linear

  vars:
    test_vm_id: 900
    test_vm_name: "replication-test"
    test_vm_storage: "local-zfs"
    replication_target: "{{ groups['proxmox_cluster_members'] | difference([inventory_hostname]) | first }}"

  tasks:
    - name: Display test VM configuration plan
      ansible.builtin.debug:
        msg: |
          Test VM Configuration for Replication
          ======================================
          VMID: {{ test_vm_id }}
          Name: {{ test_vm_name }}
          Storage: {{ test_vm_storage }} (ZFS)
          Source Node: {{ inventory_hostname }}
          Target Node: {{ replication_target }}
          Replication Interval: Every 5 minutes

    - name: Check if test VM already exists
      ansible.builtin.shell: |
        set -o pipefail
        qm list | grep -q "^\s*{{ test_vm_id }}\s"
      args:
        executable: /bin/bash
      register: vm_exists_check
      changed_when: false
      failed_when: false

    - name: Display VM existence status
      ansible.builtin.debug:
        msg: "VM {{ test_vm_id }} exists: {{ vm_exists_check.rc == 0 }}"

    - name: Stop test VM if running
      ansible.builtin.command: qm stop {{ test_vm_id }}
      register: vm_stop
      changed_when: vm_stop.rc == 0
      failed_when: false
      when: vm_exists_check.rc == 0

    - name: Wait for VM to fully stop
      ansible.builtin.pause:
        seconds: 3
      when: vm_exists_check.rc == 0

    - name: Destroy existing test VM
      ansible.builtin.command: qm destroy {{ test_vm_id }} --purge
      register: vm_destroy
      changed_when: vm_destroy.rc == 0
      failed_when: false
      when: vm_exists_check.rc == 0

    - name: Wait for VM destruction to complete
      ansible.builtin.pause:
        seconds: 5
      when: vm_exists_check.rc == 0

    - name: Verify VM is destroyed
      ansible.builtin.shell: |
        set -o pipefail
        qm list | grep -q "^\s*{{ test_vm_id }}\s"
      args:
        executable: /bin/bash
      register: vm_verify_destroy
      failed_when: vm_verify_destroy.rc == 0  # Fail if VM still exists
      retries: 3
      delay: 2
      when: vm_exists_check.rc == 0

    - name: Create lightweight test VM
      ansible.builtin.command: >
        qm create {{ test_vm_id }}
        --name {{ test_vm_name }}
        --memory 512
        --cores 1
        --net0 virtio,bridge=vmbr1
        --scsihw virtio-scsi-pci
        --scsi0 {{ test_vm_storage }}:8
        --ostype l26
        --boot order=scsi0
        --agent enabled=0
        --onboot 0
        --description "Test VM for ZFS replication validation - Phase 3"
      register: vm_create
      changed_when: vm_create.rc == 0
      retries: 3
      delay: 5

    - name: Verify test VM was created
      ansible.builtin.command: qm config {{ test_vm_id }}
      register: vm_config
      changed_when: false

    - name: Display test VM configuration
      ansible.builtin.debug:
        msg: "Test VM 900 created successfully"

    - name: Create test VM marker file
      ansible.builtin.copy:
        dest: /opt/test-vm-created
        content: |
          Test VM Created
          ===============
          VMID: {{ test_vm_id }}
          Name: {{ test_vm_name }}
          Storage: {{ test_vm_storage }}
          Created: {{ ansible_date_time.iso8601 }}
        mode: '0644'


# ===== PLAY 3: Configure ZFS Replication for Test VM =====
- name: Configure ZFS Replication for Test VM
  hosts: proxmox_cluster_masters
  become: true
  gather_facts: true
  strategy: linear

  vars:
    test_vm_id: 900
    replication_target: "{{ groups['proxmox_cluster_members'] | difference([inventory_hostname]) | first }}"
    replication_job_id: "{{ test_vm_id }}-0"
    replication_interval: "*/5"
    rate_limit: 10

  tasks:
    - name: Display replication configuration plan
      ansible.builtin.debug:
        msg: |
          ZFS Replication Configuration
          ==============================
          Job ID: {{ replication_job_id }}
          Source: {{ inventory_hostname }}
          Target: {{ replication_target }}
          Schedule: Every 5 minutes
          Rate Limit: {{ rate_limit }} MB/s

    - name: Check if replication job already exists
      ansible.builtin.shell: |
        set -o pipefail
        pvesr list | grep -q "{{ replication_job_id }}"
      args:
        executable: /bin/bash
      register: repl_exists_check
      changed_when: false
      failed_when: false

    - name: Remove existing replication job if present
      ansible.builtin.command: pvesr delete {{ replication_job_id }} --force
      when: repl_exists_check.rc == 0
      register: repl_delete
      changed_when: repl_delete.rc == 0
      failed_when: false

    - name: Wait for VM disk to be ready
      ansible.builtin.pause:
        seconds: 5

    - name: Create replication job using pvesr
      ansible.builtin.command: >
        pvesr create-local-job {{ replication_job_id }} {{ replication_target }}
        --schedule "{{ replication_interval }}"
        --rate {{ rate_limit }}
        --comment "Test replication job for VM {{ test_vm_id }} - Phase 3 validation"
      register: repl_create
      changed_when: repl_create.rc == 0
      failed_when: repl_create.rc != 0
      retries: 3
      delay: 5

    - name: Verify replication job was created
      ansible.builtin.command: pvesr list
      register: repl_list
      changed_when: false

    - name: Display replication job list
      ansible.builtin.debug:
        msg: "{{ repl_list.stdout_lines }}"

    - name: Trigger immediate replication sync
      ansible.builtin.command: pvesr run --id {{ replication_job_id }}
      register: repl_run
      changed_when: repl_run.rc == 0
      failed_when: false
      retries: 3
      delay: 5

    - name: Wait for initial replication (30 seconds)
      ansible.builtin.pause:
        seconds: 30

    - name: Check replication status
      ansible.builtin.command: pvesr status --guest {{ test_vm_id }}
      register: repl_status
      changed_when: false

    - name: Display replication status
      ansible.builtin.debug:
        msg: "{{ repl_status.stdout_lines }}"

    - name: Create replication configuration marker
      ansible.builtin.copy:
        dest: /opt/replication-config-complete
        content: |
          Replication Configuration Complete
          ===================================
          Job ID: {{ replication_job_id }}
          Source: {{ inventory_hostname }}
          Target: {{ replication_target }}
          Schedule: {{ replication_interval }}
          Rate Limit: {{ rate_limit }} MB/s
          Configured: {{ ansible_date_time.iso8601 }}

          Status: Check with: pvesr status --guest {{ test_vm_id }}
          Note: pvesr manages snapshots automatically
        mode: '0644'

# ===== PLAY 4: Configure Backup Schedule =====
- name: Configure Backup Schedule (Master Node Only)
  hosts: proxmox_cluster_masters
  become: true
  gather_facts: true
  strategy: linear

  vars:
    backup_schedule:
      storage: "nas-backup"
      schedule: "sun 02:00"
      retention: 4
      mode: "snapshot"
      compression: "zstd"
      notification_mode: "failure"

  tasks:
    - name: Display backup configuration plan
      ansible.builtin.debug:
        msg: |
          Backup Configuration
          ====================
          Storage: {{ backup_schedule.storage }}
          Schedule: {{ backup_schedule.schedule }} (Weekly, Sunday 2AM)
          Retention: {{ backup_schedule.retention }} weeks
          Mode: {{ backup_schedule.mode }}
          Compression: {{ backup_schedule.compression }}

    - name: Check if backup job already exists
      ansible.builtin.shell: |
        set -o pipefail
        pvesh get /cluster/backup | grep -q "{{ backup_schedule.storage }}"
      args:
        executable: /bin/bash
      register: backup_check
      changed_when: false
      failed_when: false

    - name: Create backup job for all VMs
      ansible.builtin.command: >
        pvesh create /cluster/backup
        --storage {{ backup_schedule.storage }}
        --schedule "{{ backup_schedule.schedule }}"
        --mode {{ backup_schedule.mode }}
        --compress {{ backup_schedule.compression }}
        --all 1
        --enabled 1
        --mailnotification {{ backup_schedule.notification_mode }}
        --prune-backups "keep-last={{ backup_schedule.retention }}"
      run_once: true
      when: backup_check.rc != 0
      changed_when: true

    - name: Verify backup job configuration
      ansible.builtin.command: pvesh get /cluster/backup
      register: backup_status
      changed_when: false

    - name: Display backup job status
      ansible.builtin.debug:
        msg: "{{ backup_status.stdout }}"

    - name: Create backup configuration completion marker
      ansible.builtin.copy:
        dest: /opt/backup-config-complete
        content: |
          Backup Configuration Complete
          =============================
          Timestamp: {{ ansible_date_time.iso8601 }}

          Backup Schedule:
            Storage: {{ backup_schedule.storage }}
            Schedule: {{ backup_schedule.schedule }}
            Retention: {{ backup_schedule.retention }} backups
            Mode: {{ backup_schedule.mode }}
            Compression: {{ backup_schedule.compression }}

          All VMs will be backed up weekly to {{ backup_schedule.storage }}
          Backups are stored in: /volume1/backups/proxmox/dump/
        mode: '0644'


# ===== PLAY 5: Final Verification =====
- name: Final Storage and Replication Verification
  hosts: proxmox_cluster_members
  become: true
  gather_facts: true

  tasks:
    - name: Verify all storage is online
      ansible.builtin.command: pvesm status
      register: final_storage_check
      changed_when: false

    - name: Verify ZFS pool health
      ansible.builtin.command: zpool status rpool
      register: final_zfs_check
      changed_when: false

    - name: Verify NFS mounts
      ansible.builtin.shell: |
        set -o pipefail
        df -h | grep nas
      args:
        executable: /bin/bash
      register: final_nfs_check
      changed_when: false
      failed_when: false

    - name: Create phase 3 completion marker
      ansible.builtin.copy:
        dest: /opt/phase3-complete
        content: |
          Phase 3: Storage Configuration Complete
          ========================================
          Node: {{ inventory_hostname }}
          Completed: {{ ansible_date_time.iso8601 }}

          Configuration Summary:
            - NFS storage mounted (3 shares)
            - ZFS replication configured (test VM 900)
            - Initial snapshot created (rpool/vm-900-disk-0@repl-init)
            - Backup schedule configured (weekly, 4-week retention)
            - Memory monitoring enabled (no swap)

          Storage Available:
            - rpool: ~857GB (local VM storage with replication)
            - nas-backup: Backups only (/volume1/backups/proxmox)
            - nas-shared: ISO, templates, snippets
            - nas-vm-storage: HA VMs (instant failover)

          Test VM:
            - VMID: 900 (replication-test)
            - Replication: Active (5-minute interval)
            - Ready for testing and validation

          Next Steps:
            1. Run validation playbook (test-replication.yml)
            2. Clean up test VM (cleanup-test-vm.yml)
            3. Proceed to Phase 4: Monitoring
        mode: '0644'

    - name: Display completion message
      ansible.builtin.debug:
        msg: |

          ✅ Phase 3 Storage Configuration Complete!
          =========================================

          All nodes configured with:
            ✓ NFS storage (3 mounts from NAS)
            ✓ ZFS replication (test VM 900 created)
            ✓ Initial snapshot (rpool/vm-900-disk-0@repl-init)
            ✓ Backup schedule (Sunday 2AM, 4-week retention)
            ✓ Memory monitoring (5-minute checks)

          Storage Summary:
            - Local ZFS (rpool): ~857GB per node (replicated for HA)
            - NAS Backup: /volume1/backups/proxmox
            - NAS Shared: /volume1/homelab-shared (ISO, templates)
            - NAS VM Storage: /volume1/homelab-data (instant failover VMs)

          Next Actions:
            1. Run: ansible-playbook test-replication.yml
            2. Validate replication works correctly
            3. Run: ansible-playbook cleanup-test-vm.yml
            4. Proceed to Phase 4 (Monitoring & Observability)
